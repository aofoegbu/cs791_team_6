# Import necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score
import matplotlib.pyplot as plt
import numpy as np
from skimage import exposure

# Define the transformations including CLAHE
transform_train = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
])

transform_test = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
])

# Apply CLAHE histogram equalization
class CLAHETransform:
    def __call__(self, img):
        img = img.numpy()
        img = exposure.equalize_adapthist(img, clip_limit=0.03)
        return torch.from_numpy(img)

# Create datasets
train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)

# Apply CLAHE to the images in the datasets
train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.Compose([transform_train, CLAHETransform()]))
test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.Compose([transform_test, CLAHETransform()]))

# Define the data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Load the pre-trained ResNet50 model
model = models.resnet50(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 10)  # Change the output layer to have 10 classes for CIFAR-10

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Function to train the model
def train_model(model, train_loader, criterion, optimizer, num_epochs=5, early_stopping_patience=3):
    best_model_weights = model.state_dict()
    best_loss = float('inf')
    consecutive_no_improvement = 0

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        epoch_loss = running_loss / len(train_loader)
        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')

        if epoch_loss < best_loss:
            best_loss = epoch_loss
            best_model_weights = model.state_dict()
            consecutive_no_improvement = 0
        else:
            consecutive_no_improvement += 1

        if consecutive_no_improvement == early_stopping_patience:
            print(f'Early stopping at epoch {epoch + 1} due to no improvement in loss.')
            break

    model.load_state_dict(best_model_weights)
    return model

# Train the model
trained_model = train_model(model, train_loader, criterion, optimizer, num_epochs=5, early_stopping_patience=3)

# Function to evaluate the model
def evaluate_model(model, test_loader):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.numpy())
            all_labels.extend(labels.numpy())

    return np.array(all_labels), np.array(all_preds)

# Evaluate the model
true_labels, predicted_labels = evaluate_model(trained_model, test_loader)

# Calculate and print metrics
accuracy = accuracy_score(true_labels, predicted_labels)
conf_matrix = confusion_matrix(true_labels, predicted_labels)

# Plot confusion matrix
plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
plt.xticks(np.arange(10), range(10))
plt.yticks(np.arange(10), range(10))
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Calculate AUC score
y_true_one_hot = np.eye(10)[true_labels]
y_score = trained_model(torch.Tensor(test_dataset.data).permute(0, 3, 1, 2) / 255.0).detach().numpy()
auc_score = roc_auc_score(y_true_one_hot, y_score, multi_class='ovr')
print(f'AUC Score: {auc_score:.4f}')
